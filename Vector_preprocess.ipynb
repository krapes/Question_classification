{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "import pymysql\n",
    "import json\n",
    "\n",
    "config_fn = './config.json'\n",
    "\n",
    "\n",
    "print(\"Import Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(config):\n",
    "    return pymysql.connect(\n",
    "        host=config['ai_db_host'],  # Database host\n",
    "        port=config['ai_db_port'],  # Database port\n",
    "        user=config['ai_db_username'],  # Database user\n",
    "        passwd=config['ai_db_password'],  # Database password\n",
    "        db=config['ai_db_name'],  # Database name\n",
    "        connect_timeout=5,\n",
    "        cursorclass=pymysql.cursors.DictCursor\n",
    "    )\n",
    "\n",
    "def pull_data():\n",
    "    with open(config_fn, \"r\") as f:\n",
    "        config = json.loads(f.read())\n",
    "    conn = connect(config)\n",
    "    sql_1 = \"SELECT rowId, question, category FROM cleanHotlineQuestionAnswer WHERE category='Compensation';\"\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(sql_1)\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(df, df2, N, v=False):\n",
    "    clusterer = KMeans(n_clusters=N)\n",
    "    clusterer.fit(df2)\n",
    "    transform = clusterer.transform(df2)\n",
    "    \n",
    "    d_center = []\n",
    "    cluster = []\n",
    "    for x in transform:\n",
    "        d_center.append(min(x)**2)\n",
    "        cluster.append(np.argmin(x))\n",
    "    df['cluster'] = cluster\n",
    "    df['d_from_center'] = d_center\n",
    "    d_center = np.array(d_center)\n",
    "    mean = np.mean(d_center)\n",
    "    std = np.std(d_center)\n",
    "\n",
    "    print(\"Mean: {}\".format(round(mean, 3)))\n",
    "    print(\"STD: {}\".format(round(std, 3)))\n",
    "    print(\"\")\n",
    "\n",
    "  \n",
    "\n",
    "    if v == True:\n",
    "        for cgroup in range(N):\n",
    "            group = df.groupby('cluster').get_group(cgroup)\n",
    "            print_clusters(group)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "def print_clusters(group):\n",
    "    std = np.std(list(group.d_from_center))\n",
    "    print(\"Found {} messages of the same form.   STD: {}\".format(len(group), std))\n",
    "    for message in group.question.head(5):\n",
    "        if group.question.count() > 1:\n",
    "            print(message)\n",
    "            print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(df, N):\n",
    "    features = list(df.features)\n",
    "    svd = TruncatedSVD(n_components=50, n_iter=2, random_state=42)\n",
    "    #svd =  PCA(n_components=2)\n",
    "    tsne = TSNE(n_components=2, perplexity=10, verbose=2)\n",
    "    feature_reduction =  make_pipeline(svd, tsne)\n",
    "\n",
    "    transformed = pd.DataFrame(feature_reduction.fit_transform(features), columns=[\"plot_cordX\", \"plot_cordY\"])\n",
    "    meanX = transformed[\"plot_cordX\"].mean()\n",
    "    meanY = transformed[\"plot_cordY\"].mean()\n",
    "    transformed[\"plot_cordX\"] = transformed[\"plot_cordX\"].divide(meanX) - 1\n",
    "    transformed[\"plot_cordY\"] = transformed[\"plot_cordY\"].divide(meanY) - 1\n",
    "    meanX = transformed[\"plot_cordX\"].mean()\n",
    "\n",
    "\n",
    "\n",
    "    df[\"plot_cordX\"] = transformed.plot_cordX\n",
    "    df[\"plot_cordY\"] = transformed.plot_cordY\n",
    "\n",
    "    q = df[\"plot_cordX\"].quantile(0.9)\n",
    "    df = df[df[\"plot_cordX\"] < q]\n",
    "    q = df[\"plot_cordY\"].quantile(0.9)\n",
    "    df = df[df[\"plot_cordY\"] < q]\n",
    "\n",
    "\n",
    "    for n in range(N):\n",
    "        plt.scatter(df[df[\"cluster\"] == n].plot_cordX, df[df[\"cluster\"] == n].plot_cordY, label=\"Class \" + str(n))\n",
    "\n",
    "\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20275 Data Points\n",
      "       category                                           question  rowId\n",
      "0  Compensation  We use time card rounding. Should we go off th...      7\n",
      "1  Compensation  Amy- Thank you for the response. Im aware of t...     22\n",
      "2  Compensation  Hourly employees- CA breaks and lunch clarific...     32\n",
      "3  Compensation  Hello, I am inquiring what the rule is for bre...     36\n",
      "4  Compensation  Severance Plan. We are updating our severance ...     45\n",
      "Vectorization Complete\n",
      "Explained variance of the SVD step: 37%     n_componets: 65\n",
      "Explained variance of the SVD step: 39%     n_componets: 70\n",
      "Explained variance of the SVD step: 41%     n_componets: 75\n",
      "Explained variance of the SVD step: 42%     n_componets: 80\n",
      "Explained variance of the SVD step: 44%     n_componets: 85\n",
      "Explained variance of the SVD step: 45%     n_componets: 90\n",
      "Explained variance of the SVD step: 47%     n_componets: 95\n",
      "Explained variance of the SVD step: 48%     n_componets: 100\n",
      "Explained variance of the SVD step: 50%     n_componets: 105\n",
      "Mean: 0.657\n",
      "STD: 0.134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pull_data())\n",
    "#df = df[df[\"category\"] == \"Compensation\"][:10000]\n",
    "print(\"Loaded {} Data Points\".format(len(df)))\n",
    "print(df.head())\n",
    "N = 20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.7 )\n",
    "X_vectoizer = vectorizer.fit_transform(list(df.question))\n",
    "print(\"Vectorization Complete\")\n",
    "\n",
    "n_components = 60\n",
    "explained_variance = 0.0\n",
    "while explained_variance < .5 and n_components < 175:\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "    X = lsa.fit_transform(X_vectoizer)\n",
    "    df[\"features\"] = list(X)\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    n_components += 5\n",
    "\n",
    "    print(\"Explained variance of the SVD step: {}%     n_componets: {}\".format(\n",
    "        int(explained_variance * 100), n_components))\n",
    "\n",
    "\n",
    "df = cluster(df, X, N, v=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file doc_vectors_compensation.tsv with 20275 entries\n",
      "Wrote file doc_meta_compensation.tsv with 20275 entries\n"
     ]
    }
   ],
   "source": [
    "vector_doc = 'doc_vectors_compensation.tsv'\n",
    "count = 0\n",
    "with open(vector_doc,'w') as w:\n",
    "    for question in X:\n",
    "        string = \"\"\n",
    "        for v in question:\n",
    "            string = string + str(v) + \"\\t\"\n",
    "        w.write(string + os.linesep)\n",
    "        count += 1\n",
    "w.close\n",
    "print(\"Wrote file {} with {} entries\".format(vector_doc, count))\n",
    "\n",
    "\n",
    "meta_doc = 'doc_meta_compensation.tsv'\n",
    "count = 0\n",
    "with open(meta_doc,'w') as w:\n",
    "    w.write(\"cluster\\tquestion\\t\" + os.linesep)\n",
    "    for question, cluster in zip(list(df.question), list(df.cluster)):\n",
    "        string = \"\"\n",
    "        string = str(cluster) + \"\\t\" + str(question) + \"\\t\"\n",
    "        w.write(string + os.linesep)  \n",
    "        count += 1\n",
    "w.close\n",
    "print(\"Wrote file {} with {} entries\".format(meta_doc, count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
